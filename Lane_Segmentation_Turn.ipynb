{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229282f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import docopt\n",
    "from docopt import docopt\n",
    "from IPython.display import HTML, Video\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66316594",
   "metadata": {},
   "source": [
    "# Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6029d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraCalibration():\n",
    "    def __init__(self, image_dir, nx, ny, debug=False):\n",
    "        fnames = glob.glob(\"{}/*\".format(image_dir))\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        \n",
    "        objp = np.zeros((nx*ny, 3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "    \n",
    "        for f in fnames:\n",
    "            img = mpimg.imread(f)\n",
    "\n",
    "            # Convert to grayscale image\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            ret, corners = cv2.findChessboardCorners(img, (nx, ny))\n",
    "            if ret:\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "            \n",
    "        shape = (img.shape[1], img.shape[0])\n",
    "        ret, self.mtx, self.dist, _, _ = cv2.calibrateCamera(objpoints, imgpoints, shape, None, None)\n",
    "    \n",
    "        if not ret:\n",
    "            raise Exception(\"Unable to calibrate camera\")\n",
    "        \n",
    "    def undistort(self, img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        return cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804f1a7",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8ca597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    \n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "class Thresholding:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, img):\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        h_channel = hls[:,:,0]\n",
    "        l_channel = hls[:,:,1]\n",
    "        s_channel = hls[:,:,2]\n",
    "        v_channel = hsv[:,:,2]\n",
    "\n",
    "        right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "        right_lane[:,:750] = 0\n",
    "\n",
    "        left_lane = threshold_abs(h_channel, 20, 30)\n",
    "        left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "        left_lane[:,550:] = 0\n",
    "\n",
    "        img2 = left_lane | right_lane\n",
    "\n",
    "        return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008c3de",
   "metadata": {},
   "source": [
    "# Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31362ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerspectiveTransformation:\n",
    "    def __init__(self):\n",
    "        self.src = np.float32([(550, 460),     # top-left\n",
    "                               (150, 720),     # bottom-left\n",
    "                               (1200, 720),    # bottom-right\n",
    "                               (770, 460)])    # top-right\n",
    "        self.dst = np.float32([(100, 0),\n",
    "                               (100, 720),\n",
    "                               (1100, 720),\n",
    "                               (1100, 0)])\n",
    "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.M_inv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "        \n",
    "    def forward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "        return cv2.warpPerspective(img, self.M, img_size, flags=flags)\n",
    "    \n",
    "    def backward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "        return cv2.warpPerspective(img, self.M_inv, img_size, flags=flags)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce9321",
   "metadata": {},
   "source": [
    "# LaneLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7384302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img):\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    return np.sum(bottom_half, axis=0)\n",
    "\n",
    "class LaneLines:\n",
    "    def __init__(self):\n",
    "        self.left_fit = None\n",
    "        self.right_fit = None\n",
    "        self.binary = None\n",
    "        self.nonzero = None\n",
    "        self.nonzerox = None\n",
    "        self.nonzeroy = None\n",
    "        self.clear_visibility = True\n",
    "        self.dir = []\n",
    "        self.left_curve_img = mpimg.imread('left_turn.png')\n",
    "        self.right_curve_img = mpimg.imread('right_turn.png')\n",
    "        self.keep_straight_img = mpimg.imread('straight.png')\n",
    "        self.left_curve_img = cv2.normalize(src=self.left_curve_img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.right_curve_img = cv2.normalize(src=self.right_curve_img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.keep_straight_img = cv2.normalize(src=self.keep_straight_img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        # Number of sliding windows\n",
    "        self.nwindows = 9\n",
    "        # Width of the the windows +/- margin\n",
    "        self.margin = 100\n",
    "        # Mininum number of pixels found to recenter window\n",
    "        self.minpix = 50\n",
    "        \n",
    "    def forward(self, img):\n",
    "        self.extract_features(img)\n",
    "        return self.fit_poly(img)\n",
    "    \n",
    "    def pixels_in_window(self, center, margin, height):\n",
    "        topleft = (center[0]-margin, center[1]-height//2)\n",
    "        bottomright = (center[0]+margin, center[1]+height//2)\n",
    "\n",
    "        condx = (topleft[0] <= self.nonzerox) & (self.nonzerox <= bottomright[0])\n",
    "        condy = (topleft[1] <= self.nonzeroy) & (self.nonzeroy <= bottomright[1])\n",
    "        return self.nonzerox[condx&condy], self.nonzeroy[condx&condy]\n",
    "    \n",
    "    def extract_features(self, img):\n",
    "        self.img = img\n",
    "        # Height of of windows - based on nwindows and image shape\n",
    "        self.window_height = np.int(img.shape[0]//self.nwindows)\n",
    "\n",
    "        # Identify the x and y positions of all nonzero pixel in the image\n",
    "        self.nonzero = img.nonzero()\n",
    "        self.nonzerox = np.array(self.nonzero[1])\n",
    "        self.nonzeroy = np.array(self.nonzero[0])\n",
    "        \n",
    "    def find_lane_pixels(self, img):\n",
    "        assert(len(img.shape) == 2)\n",
    "        \n",
    "        # Create an output image to draw on and visualize the result\n",
    "        out_img = np.dstack((img, img, img))\n",
    "\n",
    "        histogram = hist(img)\n",
    "        midpoint = histogram.shape[0]//2\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Current position to be update later for each window in nwindows\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        y_current = img.shape[0] + self.window_height//2\n",
    "\n",
    "        # Create empty lists to reveice left and right lane pixel\n",
    "        leftx, lefty, rightx, righty = [], [], [], []\n",
    "        \n",
    "        for _ in range(self.nwindows):\n",
    "            y_current -= self.window_height\n",
    "            center_left = (leftx_current, y_current)\n",
    "            center_right = (rightx_current, y_current)\n",
    "\n",
    "            good_left_x, good_left_y = self.pixels_in_window(center_left, self.margin, self.window_height)\n",
    "            good_right_x, good_right_y = self.pixels_in_window(center_right, self.margin, self.window_height)\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            leftx.extend(good_left_x)\n",
    "            lefty.extend(good_left_y)\n",
    "            rightx.extend(good_right_x)\n",
    "            righty.extend(good_right_y)\n",
    "\n",
    "            if len(good_left_x) > self.minpix:\n",
    "                leftx_current = np.int32(np.mean(good_left_x))\n",
    "            if len(good_right_x) > self.minpix:\n",
    "                rightx_current = np.int32(np.mean(good_right_x))\n",
    "\n",
    "        return leftx, lefty, rightx, righty, out_img\n",
    "    \n",
    "    def fit_poly(self, img):\n",
    "        leftx, lefty, rightx, righty, out_img = self.find_lane_pixels(img)\n",
    "\n",
    "        if len(lefty) > 1500:\n",
    "            self.left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        if len(righty) > 1500:\n",
    "            self.right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        maxy = img.shape[0] - 1\n",
    "        miny = img.shape[0] // 3\n",
    "        if len(lefty):\n",
    "            maxy = max(maxy, np.max(lefty))\n",
    "            miny = min(miny, np.min(lefty))\n",
    "\n",
    "        if len(righty):\n",
    "            maxy = max(maxy, np.max(righty))\n",
    "            miny = min(miny, np.min(righty))\n",
    "\n",
    "        ploty = np.linspace(miny, maxy, img.shape[0])\n",
    "\n",
    "        left_fitx = self.left_fit[0]*ploty**2 + self.left_fit[1]*ploty + self.left_fit[2]\n",
    "        right_fitx = self.right_fit[0]*ploty**2 + self.right_fit[1]*ploty + self.right_fit[2]\n",
    "        \n",
    "        # Visualization\n",
    "        for i, y in enumerate(ploty):\n",
    "            l = int(left_fitx[i])\n",
    "            r = int(right_fitx[i])\n",
    "            y = int(y)\n",
    "            cv2.line(out_img, (l, y), (r, y), (0, 255, 0))\n",
    "\n",
    "        lR, rR, pos = self.measure_curvature()\n",
    "\n",
    "        return out_img\n",
    "    \n",
    "    def plot(self, out_img):\n",
    "        np.set_printoptions(precision=6, suppress=True)\n",
    "        lR, rR, pos = self.measure_curvature()\n",
    "\n",
    "        value = None\n",
    "        if abs(self.left_fit[0]) > abs(self.right_fit[0]):\n",
    "            value = self.left_fit[0]\n",
    "        else:\n",
    "            value = self.right_fit[0]\n",
    "\n",
    "        if abs(value) <= 0.00015:\n",
    "            self.dir.append('F')\n",
    "        elif value < 0:\n",
    "            self.dir.append('L')\n",
    "        else:\n",
    "            self.dir.append('R')\n",
    "        \n",
    "        if len(self.dir) > 10:\n",
    "            self.dir.pop(0)\n",
    "\n",
    "        W = 400\n",
    "        H = 500\n",
    "        widget = np.copy(out_img[:H, :W])\n",
    "        widget //= 2\n",
    "        widget[0,:] = [0, 0, 255]\n",
    "        widget[-1,:] = [0, 0, 255]\n",
    "        widget[:,0] = [0, 0, 255]\n",
    "        widget[:,-1] = [0, 0, 255]\n",
    "        out_img[:H, :W] = widget\n",
    "\n",
    "        direction = max(set(self.dir), key = self.dir.count)\n",
    "        msg = \"Keep Straight Ahead\"\n",
    "        curvature_msg = \"Curvature = {:.0f} m\".format(min(lR, rR))\n",
    "        if direction == 'L':\n",
    "            y, x = self.left_curve_img[:,:,3].nonzero()\n",
    "            out_img[y, x-100+W//2] = self.left_curve_img[y, x, :3]\n",
    "            msg = \"Left Curve Ahead\"\n",
    "        if direction == 'R':\n",
    "            y, x = self.right_curve_img[:,:,3].nonzero()\n",
    "            out_img[y, x-100+W//2] = self.right_curve_img[y, x, :3]\n",
    "            msg = \"Right Curve Ahead\"\n",
    "        if direction == 'F':\n",
    "            y, x = self.keep_straight_img[:,:,3].nonzero()\n",
    "            out_img[y, x-100+W//2] = self.keep_straight_img[y, x, :3]\n",
    "\n",
    "        cv2.putText(out_img, msg, org=(10, 240), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        if direction in 'LR':\n",
    "            cv2.putText(out_img, curvature_msg, org=(10, 280), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "        cv2.putText(\n",
    "            out_img,\n",
    "            \"Good Lane Keeping\",\n",
    "            org=(10, 400),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1.2,\n",
    "            color=(0, 255, 0),\n",
    "            thickness=2)\n",
    "\n",
    "        cv2.putText(\n",
    "            out_img,\n",
    "            \"Vehicle is {:.2f} m away from center\".format(pos),\n",
    "            org=(10, 450),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.66,\n",
    "            color=(255, 255, 255),\n",
    "            thickness=2)\n",
    "\n",
    "        return out_img\n",
    "    \n",
    "    def measure_curvature(self):\n",
    "        ym = 30/720\n",
    "        xm = 3.7/700\n",
    "\n",
    "        left_fit = self.left_fit.copy()\n",
    "        right_fit = self.right_fit.copy()\n",
    "        y_eval = 700 * ym\n",
    "\n",
    "        # Compute R_curve (radius of curvature)\n",
    "        left_curveR =  ((1 + (2*left_fit[0] *y_eval + left_fit[1])**2)**1.5)  / np.absolute(2*left_fit[0])\n",
    "        right_curveR = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "\n",
    "        xl = np.dot(self.left_fit, [700**2, 700, 1])\n",
    "        xr = np.dot(self.right_fit, [700**2, 700, 1])\n",
    "        pos = (1280//2 - (xl+xr)//2)*xm\n",
    "        return left_curveR, right_curveR, pos\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46891b",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b6dff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'img' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     findLaneLines\u001b[38;5;241m.\u001b[39mprocess_video(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest5.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput2.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m---> 31\u001b[0m     findLaneLines \u001b[38;5;241m=\u001b[39m \u001b[43mFindLaneLines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     findLaneLines\u001b[38;5;241m.\u001b[39mprocess_video(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest5.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput2.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mFindLaneLines.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalibration \u001b[38;5;241m=\u001b[39m \u001b[43mCameraCalibration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcamera_cal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresholding \u001b[38;5;241m=\u001b[39m Thresholding()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m PerspectiveTransformation()\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mCameraCalibration.__init__\u001b[1;34m(self, image_dir, nx, ny, debug)\u001b[0m\n\u001b[0;32m     18\u001b[0m         imgpoints\u001b[38;5;241m.\u001b[39mappend(corners)\n\u001b[0;32m     19\u001b[0m         objpoints\u001b[38;5;241m.\u001b[39mappend(objp)\n\u001b[1;32m---> 21\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[43mimg\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m ret, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmtx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist, _, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalibrateCamera(objpoints, imgpoints, shape, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'img' referenced before assignment"
     ]
    }
   ],
   "source": [
    "class FindLaneLines:\n",
    "    def __init__(self):\n",
    "        self.calibration = CameraCalibration('camera_cal', 9, 6)\n",
    "        self.thresholding = Thresholding()\n",
    "        self.transform = PerspectiveTransformation()\n",
    "        self.lanelines = LaneLines()\n",
    "\n",
    "    def forward(self, img):\n",
    "        out_img = np.copy(img)\n",
    "        img = self.calibration.undistort(img)\n",
    "        img = self.transform.forward(img)\n",
    "        img = self.thresholding.forward(img)\n",
    "        img = self.lanelines.forward(img)\n",
    "        img = self.transform.backward(img)\n",
    "\n",
    "        out_img = cv2.addWeighted(out_img, 1, img, 0.6, 0)\n",
    "        out_img = self.lanelines.plot(out_img)\n",
    "        return out_img\n",
    "\n",
    "    def process_image(self, input_path, output_path):\n",
    "        img = mpimg.imread(input_path)\n",
    "        out_img = self.forward(img)\n",
    "        mpimg.imsave(output_path, out_img)\n",
    "\n",
    "    def process_video(self, input_path, output_path):\n",
    "        clip = VideoFileClip(input_path)\n",
    "        out_clip = clip.fl_image(self.forward)\n",
    "        out_clip.write_videofile(output_path, audio=False)\n",
    "        \n",
    "def main():\n",
    "    findLaneLines = FindLaneLines()\n",
    "    findLaneLines.process_video(\"test5.mp4\",\"output2.mp4\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfeec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
